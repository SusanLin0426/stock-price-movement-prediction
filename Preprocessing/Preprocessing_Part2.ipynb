{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:41:35.246199Z",
     "start_time": "2022-04-01T07:41:31.446946Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 處理股價\n",
    "導入微股力交易數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:45:11.282215Z",
     "start_time": "2022-04-01T07:42:34.412466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock = pd.read_csv('./bda2024_mid_dataset/bda2024_微股力_個股交易數據-2年.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選0050為此次預測標的，用to_datetime調整時間顯示方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:46:48.948041Z",
     "start_time": "2022-04-01T07:46:48.803057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yuanta = stock[stock['stock_symbol'] == '0050']\n",
    "yuanta['date'] = pd.to_datetime(yuanta['date']).dt.date\n",
    "yuanta = yuanta.sort_values(by = 'date').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先整理表格內容，增加兩個欄位分別為：\n",
    "1.  five_day_change_pct：表示今日與前五日收盤價的價格變化（調整window來改變時間差）\n",
    "2.  label：表示今日與五日前收盤價的漲跌標籤，1代表漲，-1代表跌，0代表持平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:47:55.104750Z",
     "start_time": "2022-04-01T07:47:55.083647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yuanta = yuanta[['stock_symbol', 'date', 'close']]\n",
    "yuanta['five_day_change_pct'] = yuanta['close'].rolling(window=5).apply(lambda x: (x.iloc[1]-x.iloc[0])/x.iloc[0]*100)\n",
    "yuanta['label'] = yuanta['five_day_change_pct'].apply(lambda x: '1' if x > 2 else ('-1' if x < -2 else '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:47:56.778524Z",
     "start_time": "2022-04-01T07:47:56.740391Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>five_day_change_pct</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0050</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>140.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0050</td>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>139.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0050</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>139.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0050</td>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>138.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0050</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>134.00</td>\n",
       "      <td>-0.569598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0050</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>141.65</td>\n",
       "      <td>4.707613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0050</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>141.20</td>\n",
       "      <td>-0.737619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0050</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>142.80</td>\n",
       "      <td>-0.141543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0050</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>143.75</td>\n",
       "      <td>0.389794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0050</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>143.95</td>\n",
       "      <td>-0.317684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stock_symbol        date   close  five_day_change_pct label\n",
       "0           0050  2022-03-01  140.45                  NaN     0\n",
       "1           0050  2022-03-02  139.65                  NaN     0\n",
       "2           0050  2022-03-03  139.95                  NaN     0\n",
       "3           0050  2022-03-04  138.45                  NaN     0\n",
       "4           0050  2022-03-07  134.00            -0.569598     0\n",
       "..           ...         ...     ...                  ...   ...\n",
       "480         0050  2024-02-20  141.65             4.707613     1\n",
       "481         0050  2024-02-21  141.20            -0.737619     0\n",
       "482         0050  2024-02-22  142.80            -0.141543     0\n",
       "483         0050  2024-02-23  143.75             0.389794     0\n",
       "484         0050  2024-02-26  143.95            -0.317684     0\n",
       "\n",
       "[485 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yuanta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 2022-2024 年 的 485 個交易日中，漲跌變化的個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:48:12.477455Z",
     "start_time": "2022-04-01T07:48:12.468291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     442\n",
       "1      22\n",
       "-1     21\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yuanta['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 處理文章資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先讀取新聞及論壇資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_df(filepath, preview=True):\n",
    "    print(f\"\\n----- Loading {filepath}... -----\")\n",
    "    df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    print(f\"Size of dataframe: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if preview:\n",
    "        print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:55:06.322404Z",
     "start_time": "2022-04-01T07:55:04.370091Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_內容數據_新聞1.csv... -----\n",
      "Size of dataframe: (179449, 9)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url']\n",
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_內容數據_新聞2.csv... -----\n",
      "Size of dataframe: (15114, 9)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url']\n",
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_內容數據_新聞3.csv... -----\n",
      "Size of dataframe: (290929, 9)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url']\n",
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_討論數據_dcard.csv... -----\n",
      "Size of dataframe: (231320, 10)\n",
      "Columns: ['id', 'forum', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_討論數據_mobile01-1.csv... -----\n",
      "Size of dataframe: (48725, 10)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_討論數據_mobile01-2.csv... -----\n",
      "Size of dataframe: (157939, 10)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading ./bda2024_mid_dataset/bda2024_202203-202402_討論數據_ptt.csv... -----\n",
      "Size of dataframe: (50805, 9)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url']\n"
     ]
    }
   ],
   "source": [
    "news1_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_內容數據_新聞1.csv\", preview=False)\n",
    "news2_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_內容數據_新聞2.csv\", preview=False)\n",
    "news3_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_內容數據_新聞3.csv\", preview=False)\n",
    "news_df = pd.concat([news1_df, news2_df, news3_df], ignore_index=True)\n",
    "\n",
    "disc_dcard_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_討論數據_dcard.csv\", preview=False)\n",
    "disc_dcard_df.rename(columns={'forum': 'p_type'}, inplace=True)    # Repair column name typo in data\n",
    "disc_m1_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_討論數據_mobile01-1.csv\", preview=False)\n",
    "disc_m2_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_討論數據_mobile01-2.csv\", preview=False)\n",
    "disc_ptt_df = load_df(\"./bda2024_mid_dataset/bda2024_202203-202402_討論數據_ptt.csv\", preview=False)\n",
    "disc_df = pd.concat([disc_dcard_df, disc_m1_df, disc_m2_df, disc_ptt_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 篩選出標題及內文提及「元大台灣50」或「0050」的文章\n",
    "* drop掉論壇文章集中關於content type的欄位（content type記錄對應的內容是評論or文章等等），把評論集和新聞集concat一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:54:54.083756Z",
     "start_time": "2022-04-01T07:54:53.652438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_df_yuanta = news_df[(news_df['title'].str.contains('0050') | news_df['title'].str.contains('元大台灣50')) |\n",
    "                      (news_df['content'].str.contains('0050') | news_df['content'].str.contains('元大台灣50'))].reset_index(drop=True)\n",
    "# news_df_yuanta\n",
    "\n",
    "disc_df_yuanta = disc_df[(disc_df['title'].str.contains('0050') | disc_df['title'].str.contains('元大台灣50')) |\n",
    "                      (disc_df['content'].str.contains('0050') | disc_df['content'].str.contains('元大台灣50'))].reset_index(drop = True)\n",
    "# disc_df_yuanta\n",
    "\n",
    "disc_df_yuanta = disc_df_yuanta.drop(columns=['content_type'])\n",
    "df_yuanta = pd.concat([news_df_yuanta, disc_df_yuanta], ignore_index=True)\n",
    "# df_yuanta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 將第 n 天的文章與第 n+5 的股市漲跌標籤合併，並且只保留我們需要的欄位資訊（post_time, title, content, label）\n",
    "* 用datetime.timedelta(days=5)調整影響天數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:54:57.360875Z",
     "start_time": "2022-04-01T07:54:57.319883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_yuanta['post_time'] = pd.to_datetime(df_yuanta['post_time']).dt.date\n",
    "yuanta['date-5'] = yuanta['date'] - datetime.timedelta(days=5)\n",
    "df_yuanta = pd.merge(df_yuanta, yuanta, left_on='post_time', right_on='date-5')[['post_time', 'title', 'content', 'label']]\n",
    "# df_yuanta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "漲、跌、持平的文章總數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7544\n",
       "-1     620\n",
       "1      428\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yuanta['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分出「漲」(label=1) 和「跌」(label=-1) 的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_yuanta_up = df_yuanta[df_yuanta['label'] == '1']\n",
    "df_yuanta_up.to_csv('df_yuanta_up.csv',index=False) # 428 rows × 4 columns\n",
    "df_yuanta_down = df_yuanta[df_yuanta['label'] == '-1']\n",
    "# df_yuanta_down # 620 rows × 4 columns\n",
    "df_yuanta_stay = df_yuanta[df_yuanta['label'] == '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 訓練集文章向量化處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 首先先進行斷詞處理，以下我們會先實作幾個步驟：\n",
    "    1. 正則表示法清除多餘字元：先移除文章中符號、英數字，只保留中文字元\n",
    "    2. 斷句：由於 monpa 在處理 200 字以上字串的斷詞時可能會出現錯誤結果，因此我們統一對長文章先進行斷句拆成較短的句子組成的 list\n",
    "    3. 斷詞：透過 monpa 對斷句結果中的所有句子進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import monpa\n",
    "from monpa import utils\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:55:42.704611Z",
     "start_time": "2022-04-01T07:55:42.697418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 這個function用來將字串以正則化處理去除中文字元以外的字元\n",
    "def clearSentence(sentence):\n",
    "    return re.sub(r'[^\\u4e00-\\u9fa5]+', '', sentence)\n",
    "\n",
    "# 我們從stopwords-zh.txt這個檔案中匯入繁體中文的停用詞\n",
    "with open('stopwords-zh.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines() \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這邊先嘗試用 2023 年 1 月至 5 月的文章資料來訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 設定訓練資料集的開始日期與結束日期\n",
    "train_startDate = datetime.date(2023, 1, 1)\n",
    "train_endDate = datetime.date(2023, 5, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練集資料數量（透過上面時間篩選後，被選為訓練集的資料）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「漲」的訓練文章數： 56\n",
      "「跌」的訓練文章數： 46\n"
     ]
    }
   ],
   "source": [
    "print(\"「漲」的訓練文章數：\",len(list(df_yuanta_up[df_yuanta_up['post_time'].between(train_startDate, train_endDate)].index)))\n",
    "print(\"「跌」的訓練文章數：\",len(list(df_yuanta_down[df_yuanta_down['post_time'].between(train_startDate, train_endDate)].index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 透過monpa對文章進行斷詞處理，並將個別斷詞結果寫在tokenStr這個字串變數中，最後再將訓練集中所有字串存在tokenStr_list中\n",
    "def generate_tokenized_text(dataset, start_date, end_date):\n",
    "    train_tokenStr_list = []\n",
    "    for i in list(dataset[dataset['post_time'].between(start_date, end_date)].index):\n",
    "        try:\n",
    "            sentence_list = utils.short_sentence(dataset['content'][i])\n",
    "            tokenStr = str()\n",
    "            for sentence in sentence_list:\n",
    "                sentence = clearSentence(sentence)\n",
    "                tokens = monpa.cut(sentence)\n",
    "                tokenStr += ' '.join(tokens)\n",
    "            train_tokenStr_list.append(tokenStr)\n",
    "        except:\n",
    "            train_tokenStr_list.append('')\n",
    "    return train_tokenStr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "個別針對「漲」和「跌」的文章斷字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tokenStr_list_up = generate_tokenized_text(df_yuanta_up, train_startDate, train_endDate)\n",
    "train_tokenStr_list_down = generate_tokenized_text(df_yuanta_down, train_startDate, train_endDate)\n",
    "\n",
    "# train_tokenStr_list_up 代表漲的文章的斷字\n",
    "# train_tokenStr_list_down 代表跌的文章的斷字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章向量化處理：我們透過 sklearn 套件中 TfidfVectorizer 將斷詞結果去除stop word後轉為空間向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:57:40.475048Z",
     "start_time": "2022-04-01T07:57:39.861749Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer_before_chi = TfidfVectorizer(stop_words=stopwords)\n",
    "X_train_up = vectorizer_before_chi.fit_transform(train_tokenStr_list_up)\n",
    "X_train_up = pd.DataFrame(X_train_up.toarray(),columns=vectorizer_before_chi.get_feature_names_out())\n",
    "# X_train_up # 56 rows × 1324 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_down = vectorizer_before_chi.fit_transform(train_tokenStr_list_down)\n",
    "X_train_down = pd.DataFrame(X_train_down.toarray(),columns=vectorizer_before_chi.get_feature_names_out())\n",
    "# X_train_down # 56 rows × 1324 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看到使用全部的斷詞結果去組成空間向量時稀疏性會非常大，在後續預測時效率會很低，因此我們需要選擇對分類結果有較顯著影響的詞彙作為向量空間的維度，以下我們透過 Chi-square 計算各詞彙與漲跌標籤的獨立性作為選擇向量空間維度的依據。\n",
    "* 我們先假設使用chi-square挑出前1000大的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T07:57:49.192925Z",
     "start_time": "2022-04-01T07:57:49.005318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_up = df_yuanta_up[df_yuanta_up['post_time'].between(train_startDate, train_endDate)]['label']\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k = 1000)\n",
    "chi2_selector.fit(X_train_up, y_train_up)\n",
    "kbest_vocabs_up = X_train_up.columns[chi2_selector.get_support()]\n",
    "X_train_up = X_train_up[kbest_vocabs_up]\n",
    "# X_train_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_down = df_yuanta_down[df_yuanta_down['post_time'].between(train_startDate, train_endDate)]['label']\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k = 1000)\n",
    "chi2_selector.fit(X_train_down, y_train_down)\n",
    "kbest_vocabs_down = X_train_down.columns[chi2_selector.get_support()]\n",
    "X_train_down = X_train_down[kbest_vocabs_down]\n",
    "# X_train_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著刪掉在漲和跌的兩個向量空間中同樣的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "刪掉同樣的後，漲和跌的個別feature數量： 645\n",
      "總feature數量： 1290\n"
     ]
    }
   ],
   "source": [
    "set_up = set(kbest_vocabs_up)\n",
    "set_down = set(kbest_vocabs_down)\n",
    "\n",
    "common_words = set_up.intersection(set_down)\n",
    "\n",
    "unique_up = set_up - common_words\n",
    "unique_down = set_down - common_words\n",
    "\n",
    "unique_up_list = list(unique_up)\n",
    "unique_down_list = list(unique_down)\n",
    "\n",
    "# unique_up_list 代表漲的feature\n",
    "# unique_down_list 代表跌的feature\n",
    "\n",
    "print('刪掉同樣的後，漲和跌的個別feature數量：', len(unique_up_list))\n",
    "\n",
    "total_feature = unique_up_list + unique_down_list\n",
    "print('總feature數量：', len(total_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把所有跟元大相關的漲跌文章各自的title和content合併起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuanta_combine_up = df_yuanta_up.title + df_yuanta_up.content\n",
    "yuanta_combine_down = df_yuanta_down.title + df_yuanta_down.content\n",
    "yuanta_combine_stay = df_yuanta_stay.title + df_yuanta_stay.content\n",
    "\n",
    "yuanta_combine_up = yuanta_combine_up.dropna()\n",
    "yuanta_combine_down = yuanta_combine_down.dropna()\n",
    "yuanta_combine_stay = yuanta_combine_stay.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用CountVectorizer，計算漲跌文章中是否出現前面提取出的unique feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary = total_feature, binary=True)\n",
    "\n",
    "yuanta_up_vector = vectorizer.fit_transform(yuanta_combine_up)\n",
    "yuanta_down_vector = vectorizer.fit_transform(yuanta_combine_down)\n",
    "yuanta_stay_vector = vectorizer.fit_transform(yuanta_combine_stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8587, 1292)\n"
     ]
    }
   ],
   "source": [
    "df_yuanta_up = df_yuanta_up.reset_index(drop=True)\n",
    "df_yuanta_down = df_yuanta_down.reset_index(drop=True)\n",
    "df_yuanta_stay = df_yuanta_stay.reset_index(drop=True)\n",
    "\n",
    "yuanta_up_vector = pd.DataFrame(yuanta_up_vector.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "yuanta_up_vector['label'] = 1\n",
    "yuanta_up_vector['post_time'] = df_yuanta_up['post_time']\n",
    "\n",
    "yuanta_down_vector = pd.DataFrame(yuanta_down_vector.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "yuanta_down_vector['label'] = -1\n",
    "yuanta_down_vector['post_time'] = df_yuanta_down['post_time']\n",
    "\n",
    "yuanta_stay_vector = pd.DataFrame(yuanta_stay_vector.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "yuanta_stay_vector['label'] = 0\n",
    "yuanta_stay_vector['post_time'] = df_yuanta_stay['post_time']\n",
    "\n",
    "yuanta_vector = pd.concat([yuanta_up_vector, yuanta_down_vector], axis=0)\n",
    "yuanta_vector = pd.concat([yuanta_vector, yuanta_stay_vector], axis=0)\n",
    "print(yuanta_vector.shape)\n",
    "\n",
    "yuanta_vector.to_csv('yuanta_vector.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我們就用到這裡以上！！\n",
    "下面是學姊給的去年的code，還沒有全部修改完，看你們想要怎麼調整！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 測試集文章向量化處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 接著我們可以透過前面訓練的向量維度將 2022 年 11 月到 2023 年 6 月的文章也轉成 tf-idf 的向量空間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:03:06.907964Z",
     "start_time": "2022-04-01T08:02:33.513112Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 首先先計算testing文章個別的tfidf\n",
    "test_startDate = datetime.date(2023, 6, 1)\n",
    "test_endDate = datetime.date(2022,10,31)\n",
    "\n",
    "test_tokenStr_list = []\n",
    "for i in list(df_yuanta_up[df_yuanta_up['post_time'].between(test_startDate, test_endDate)].index):\n",
    "    try:\n",
    "        txt = clearSentence(df_yuanta_up['content'][i])\n",
    "        sentence_list = utils.short_sentence(txt)\n",
    "        tokenStr = str()\n",
    "        for sentence in sentence_list:\n",
    "            tokens = monpa.cut(sentence)\n",
    "            tokenStr += ' '.join(tokens)\n",
    "        test_tokenStr_list.append(tokenStr)\n",
    "    except:\n",
    "        test_tokenStr_list.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:03:07.008158Z",
     "start_time": "2022-04-01T08:03:06.910009Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 接著將結果透過df.reindex這個方法映射到訓練集的向量空間中\n",
    "y_test = df_yuanta_up[df_yuanta_up['post_time'].between(test_startDate, test_endDate)]['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "X_test = vectorizer.fit_transform(test_tokenStr_list)\n",
    "X_test = pd.DataFrame(X_test.toarray(),columns=vectorizer.get_feature_names())\n",
    "X_test = X_test.reindex(kbest_vocabs_up, axis=1, fill_value=0)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 建立預測模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:05:59.291197Z",
     "start_time": "2022-04-01T08:05:59.175081Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:07:14.508414Z",
     "start_time": "2022-04-01T08:07:10.967490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=7, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 檢視預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:07:55.402644Z",
     "start_time": "2022-04-01T08:07:55.367541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10月份預測準確率: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "test_label = yuanta[yuanta['年月日-1'].between(test_startDate, test_endDate)]['label']\n",
    "\n",
    "test_data = bbs23_yuanta[bbs23_yuanta['post_time'].between(test_startDate, test_endDate)]\n",
    "test_data['predict_label'] = clf.predict(X_test)\n",
    "predict_label = pd.merge(\n",
    "    yuanta[yuanta['年月日-1'].between(test_startDate, test_endDate)], \n",
    "    test_data.groupby(['post_time', 'predict_label']).count().sort_values('label', ascending = False).sort_index(level=[0], sort_remaining=False).groupby(level=0).head(1).reset_index(), \n",
    "    left_on='年月日-1', right_on='post_time', how='left').fillna(method='ffill').fillna(method='bfill')['predict_label']\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('{}月份預測準確率:'.format(test_startDate.month), accuracy_score(test_label, predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:08:00.963039Z",
     "start_time": "2022-04-01T08:08:00.947535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>漲</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>漲</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>漲</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>漲</td>\n",
       "      <td>漲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>漲</td>\n",
       "      <td>漲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>漲</td>\n",
       "      <td>漲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>漲</td>\n",
       "      <td>漲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>漲</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>漲</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>漲</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>跌</td>\n",
       "      <td>跌</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label predict_label\n",
       "0      跌             跌\n",
       "1      漲             跌\n",
       "2      漲             跌\n",
       "3      漲             跌\n",
       "4      跌             跌\n",
       "5      跌             跌\n",
       "6      跌             跌\n",
       "7      跌             跌\n",
       "8      漲             漲\n",
       "9      漲             漲\n",
       "10     跌             跌\n",
       "11     跌             跌\n",
       "12     漲             漲\n",
       "13     漲             漲\n",
       "14     漲             跌\n",
       "15     跌             跌\n",
       "16     跌             跌\n",
       "17     漲             跌\n",
       "18     漲             跌\n",
       "19     跌             跌\n",
       "20     跌             跌"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([test_label.reset_index(drop=True), predict_label]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 同學們可以嘗試調整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 漲跌標籤的判斷%數（重要！！）\n",
    "2. 文章與股價時間區間的移動天數（小時數）\n",
    "3. 使用不同斷詞工具（推薦中研院CKIPTransformer）\n",
    "4. 特徵選擇的其他方法（lift、、MI、、LLR...）\n",
    "5. 特徵選擇的數量（太少會有很高的 false positive，太高則效率差）\n",
    "6. 嘗試用看看不同分類模型\n",
    "7. 改變投票方法，漲跌平三者的權重應該一樣嗎？\n",
    "\n",
    "      GOOD LUCK!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
